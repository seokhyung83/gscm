{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4b3d69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import os, random, time\n",
    "import prophet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from scipy.stats import mode\n",
    "#from datetime import date\n",
    "#import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b67921f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4_P34_생산실적_2020.csv', '5_P34_생산계획_210405.csv', '6_P34_재고실적_210415.csv', 'DMF0035_MktFcstWaterfall(Mkt Fcst Waterfall)_20210412132805.csv', 'DMF0035_MktFcstWaterfall(Mkt Fcst Waterfall)_20210412174616.csv', 'X_Product.csv', 'X_Sales.csv', 'Y_Inven.csv']\n"
     ]
    }
   ],
   "source": [
    "f_list = os.listdir('./data/')\n",
    "f_list.sort()\n",
    "print(f_list)\n",
    "dt_info = np.vstack((np.column_stack((np.repeat(2020,53),np.arange(1,54))), np.column_stack((np.repeat(2021,21),np.arange(1,22)))))\n",
    "end_info= 66 ## '21 WW13'\n",
    "\n",
    "def last_calendar_week(year):\n",
    "    _year, week, _day = datetime.date(year, 12, 31).isocalendar()\n",
    "    return week"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae6ef4f",
   "metadata": {},
   "source": [
    "#### 재고실적 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a143f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_file = pd.read_csv('./data/'+f_list[2], encoding='euc-kr', thousands=',')\n",
    "#tmp_title = ['DATE', 'MONTH', 'WW','DAY', 'IN_CELL', 'OUT_CELL', 'INVENTORY_CELL', 'IN_PACK_D', 'OUT_PACK_D', 'INVENTORY_PACK_D']                \n",
    "tmp_Y_inven = pd.DataFrame({'YEAR' : tmp_file['DATE'].str.slice(0,4).astype(int), #pd.to_datetime(tmp_file['DATE']).dt.isocalendar().year,\n",
    "                            'WW' : pd.to_datetime(tmp_file['DATE'], format='%Y-%m-%d').dt.isocalendar().week,\n",
    "                            'DATE' : tmp_file['DATE'],\n",
    "                            'INVENTORY_PACK_D' : tmp_file['INVENTORY_PACK_D']})\n",
    "\n",
    "#tmp_inven_qty = list()\n",
    "for i in range(0, end_info):\n",
    "    \n",
    "    if last_calendar_week(dt_info[i][0]) == dt_info[i][1]:    \n",
    "        tmp_y_dta = tmp_Y_inven[(tmp_Y_inven['WW']==dt_info[i][1])] #(tmp_Y_inven['YEAR']==dt_info[i][0]) & \n",
    "    else:\n",
    "        tmp_y_dta = tmp_Y_inven[(tmp_Y_inven['YEAR']==dt_info[i][0]) & (tmp_Y_inven['WW']==dt_info[i][1])] #\n",
    "\n",
    "    #tmp_inven_qty.append(tmp_y_dta['INVENTORY_PACK_D'].mean())\n",
    "    d_week = np.array(pd.to_datetime(tmp_y_dta['DATE'], format='%Y-%m-%d').dt.dayofweek)\n",
    "    #tmp_y_dta['INVENTORY_PACK_D']#.iloc[0,:]#[0, (np.where(d_week == 6)[0][0]-1)]\n",
    "    for j in range(0 ,len(d_week)):\n",
    "        if d_week[j] == 6:\n",
    "            tmp_inven_qty = tmp_y_dta['INVENTORY_PACK_D'].iloc[j]\n",
    "    tmp_inven_qty = np.array((dt_info[i][0], dt_info[i][1], tmp_inven_qty))\n",
    "    if i==0:\n",
    "        inven_dta_qty = tmp_inven_qty\n",
    "    else:\n",
    "        inven_dta_qty = np.vstack((inven_dta_qty, tmp_inven_qty))\n",
    "    #print(dt_info[i], tmp_y_dta.shape)\n",
    "cnt = 1\n",
    "for i in range(9, end_info):\n",
    "    tmp_inven_qty = []\n",
    "    for j in range(0, 9):\n",
    "        tmp_inven_qty.append(inven_dta_qty[(i-j),2])\n",
    "    if cnt ==1 :\n",
    "        tmp_inven_dta = tmp_inven_qty\n",
    "    else:\n",
    "        tmp_inven_dta = np.vstack((tmp_inven_dta, tmp_inven_qty))\n",
    "    cnt+=1\n",
    "    \n",
    "#inven_dta = pd.DataFrame(dt_info[9:end_info])\n",
    "##inven_dta['INVENTORY_PACK_D'] = tmp_inven_qty\n",
    "inven_dta = pd.DataFrame(dt_info[9:end_info])\n",
    "inven_dta = pd.concat([inven_dta, pd.DataFrame(tmp_inven_dta)], axis=1)\n",
    "#inven_dta \n",
    "inven_dta.columns = list(['YEAR', 'WW']) + list(map(lambda x : \"INVENTORY\" if x == 0  else \"prev_INVENTORY_\"+str(x), range(0, 9))) #list(['YEAR', 'WW', 'INVENTORY_PACK_D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c23d5e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "inven_dta.to_csv('./data/Y_Inven.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a3d18e",
   "metadata": {},
   "source": [
    "#### 생산실적 / 생산계획 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc0d0236",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_file = pd.read_csv('./data/'+f_list[1], thousands=',')\n",
    "tmp_title = ['PLAN_START_YYYYMMDD','YYYYMMDD', 'QTY']\n",
    "X_product_plan = tmp_file[tmp_title].copy() \n",
    "X_product_plan['PLAN_WW'] = pd.to_datetime(tmp_file['PLAN_START_YYYYMMDD'], format='%Y%m%d').dt.isocalendar().week\n",
    "X_product_plan['PLAN_YEAR'] = pd.to_datetime(tmp_file['PLAN_START_YYYYMMDD'], format='%Y%m%d').dt.isocalendar().year\n",
    "X_product_plan['TARGET_WW'] = pd.to_datetime(tmp_file['YYYYMMDD'], format='%Y%m%d').dt.isocalendar().week\n",
    "X_product_plan['TARGET_YEAR'] = pd.to_datetime(tmp_file['YYYYMMDD'], format='%Y%m%d').dt.isocalendar().year\n",
    "X_product_plan.head()\n",
    "\n",
    "prev_name = list(map(lambda x : 'Prev_Product_'+str(x), np.arange(1, 9, 1)))\n",
    "post_name = list(map(lambda x : 'Post_Product_'+str(x), np.arange(1, 9, 1)))\n",
    "var_name  = list(map(lambda x : 'Var_Product_'+str(x),  np.arange(1, 9, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "122f8c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIVISION_ID</th>\n",
       "      <th>PLAN_START_YYYYMMDD</th>\n",
       "      <th>PLAN_TYPE</th>\n",
       "      <th>SEQ</th>\n",
       "      <th>OPERATION_GROUP</th>\n",
       "      <th>SCM_SITE_ID</th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>LINE_ID</th>\n",
       "      <th>OPERATION_ID</th>\n",
       "      <th>MEASURE</th>\n",
       "      <th>YYYYMMDD</th>\n",
       "      <th>WW</th>\n",
       "      <th>YYYYMM</th>\n",
       "      <th>QTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [DIVISION_ID, PLAN_START_YYYYMMDD, PLAN_TYPE, SEQ, OPERATION_GROUP, SCM_SITE_ID, ITEM_ID, LINE_ID, OPERATION_ID, MEASURE, YYYYMMDD, WW, YYYYMM, QTY]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_file[tmp_file['PLAN_START_YYYYMMDD']==20200308]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "960f945d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PLAN_START_YYYYMMDD  YYYYMMDD  QTY  PLAN_WW  PLAN_YEAR  TARGET_WW  \\\n",
      "2637             20200302  20200427  154       10       2020         18   \n",
      "2638             20200302  20200428  154       10       2020         18   \n",
      "2639             20200302  20200429  154       10       2020         18   \n",
      "2640             20200302  20200430  154       10       2020         18   \n",
      "2641             20200302  20200501  154       10       2020         18   \n",
      "2642             20200302  20200502  154       10       2020         18   \n",
      "2643             20200302  20200503  156       10       2020         18   \n",
      "\n",
      "      TARGET_YEAR  \n",
      "2637         2020  \n",
      "2638         2020  \n",
      "2639         2020  \n",
      "2640         2020  \n",
      "2641         2020  \n",
      "2642         2020  \n",
      "2643         2020  \n",
      "1080\n"
     ]
    }
   ],
   "source": [
    "print(X_product_plan[(X_product_plan['PLAN_WW']==10) & (X_product_plan['TARGET_WW']==18) & (X_product_plan['PLAN_YEAR']==2020)])\n",
    "print(X_product_plan[(X_product_plan['PLAN_WW']==10) & (X_product_plan['TARGET_WW']==18) & (X_product_plan['PLAN_YEAR']==2020)].iloc[:,2].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109bce2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e58b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_file = pd.read_csv('./data/'+f_list[0], encoding='euc-kr', thousands=',')\n",
    "tmp_title = ['Prod Type','Material', 'Basic Date', 'Plan Date', 'Plan Qty', 'Result Qty']\n",
    "tmp_p_real1 = tmp_file[tmp_title].copy()\n",
    "tmp_p_real1['YEAR'] = pd.to_datetime(tmp_file['Plan Date']).dt.isocalendar().year\n",
    "tmp_p_real1['WW'] = pd.to_datetime(tmp_file['Plan Date']).dt.isocalendar().week\n",
    "X_product_actual = tmp_p_real1[(tmp_p_real1['YEAR']==2020)& (tmp_p_real1['Material']=='APVCCCMA0-A2-A01')]  #(tmp_p_real1['Prod Type']=='MASS') & \n",
    "\n",
    "cnt = 0\n",
    "r_QTY_sum = list()\n",
    "for t in range(0, end_info): #53):# \n",
    "    TW=dt_info[t,1]; TY=dt_info[t,0]    \n",
    "    if any((X_product_actual['YEAR']==TY) & (X_product_actual['WW']==TW)):\n",
    "        r_QTY_sum.append(X_product_actual[(X_product_actual['YEAR']==TY) & (X_product_actual['WW']==TW)]['Result Qty'].sum())\n",
    "    else:\n",
    "        r_QTY_sum.append(None)\n",
    "\n",
    "        \n",
    "################################################################################################\n",
    "r_QTY_sum[53:66] = [842,1285,1254,1102,1274,1243,1327,870,1077,1351,1170,837,992]\n",
    "################################################################################################\n",
    "#product_dta['Products'] = r_QTY_sum\n",
    "\n",
    "#### 생산계획 ####\n",
    "tmp_file = pd.read_csv('./data/'+f_list[1], thousands=',')\n",
    "tmp_title = ['PLAN_START_YYYYMMDD','YYYYMMDD', 'QTY']\n",
    "X_product_plan = tmp_file[tmp_title].copy() \n",
    "X_product_plan['PLAN_WW'] = pd.to_datetime(tmp_file['PLAN_START_YYYYMMDD'], format='%Y%m%d').dt.isocalendar().week\n",
    "X_product_plan['PLAN_YEAR'] = pd.to_datetime(tmp_file['PLAN_START_YYYYMMDD'], format='%Y%m%d').dt.isocalendar().year\n",
    "X_product_plan['TARGET_WW'] = pd.to_datetime(tmp_file['YYYYMMDD'], format='%Y%m%d').dt.isocalendar().week\n",
    "X_product_plan['TARGET_YEAR'] = pd.to_datetime(tmp_file['YYYYMMDD'], format='%Y%m%d').dt.isocalendar().year\n",
    "X_product_plan.head()\n",
    "\n",
    "prev_name = list(map(lambda x : 'Prev_Product_'+str(x), np.arange(1, 9, 1)))\n",
    "post_name = list(map(lambda x : 'Post_Product_'+str(x), np.arange(1, 9, 1)))\n",
    "var_name  = list(map(lambda x : 'Var_Product_'+str(x),  np.arange(1, 9, 1)))\n",
    "\n",
    "cnt = 0\n",
    "for t in range(9, end_info): #53):# \n",
    "    QTY_prev = list()\n",
    "    QTY_post = list()    \n",
    "    QTY_var = list()    \n",
    "    \n",
    "    for j in range(1, 9):        \n",
    "        target_y = dt_info[t][0] ; target_w = dt_info[t][1]\n",
    "        post_y = dt_info[t+j][0]; post_w = dt_info[t+j][1]; \n",
    "        #prev_y = dt_info[t-j][0]; prev_w = dt_info[t-j][1];        \n",
    "        #print(post_y,post_w, \" / \", prev_y, prev_w)\n",
    "        #QTY_prev.append(X_product_plan[(X_product_plan['PLAN_YEAR']==prev_y) & (X_product_plan['PLAN_WW']==prev_w) & (X_product_plan['TARGET_YEAR']==target_y) & (X_product_plan['TARGET_WW']==target_w)]['QTY'].sum())        \n",
    "        QTY_prev.append(r_QTY_sum[t-j])\n",
    "        QTY_post.append(X_product_plan[(X_product_plan['PLAN_YEAR']==target_y) & (X_product_plan['PLAN_WW']==target_w) & (X_product_plan['TARGET_YEAR']==post_y) & (X_product_plan['TARGET_WW']==post_w)]['QTY'].sum())\n",
    "\n",
    "    for j in range(1, 9):        \n",
    "        target_y = dt_info[t][0] ; target_w = dt_info[t][1]\n",
    "        prev_y = dt_info[t-j][0]; prev_w = dt_info[t-j][1];        \n",
    "        #print(post_y,post_w, \" / \", prev_y, prev_w)\n",
    "        QTY_var.append(X_product_plan[(X_product_plan['PLAN_YEAR']==prev_y) & (X_product_plan['PLAN_WW']==prev_w) & (X_product_plan['TARGET_YEAR']==target_y) & (X_product_plan['TARGET_WW']==target_w)]['QTY'].sum())\n",
    "\n",
    "    tmp_QTY = QTY_prev + QTY_post + QTY_var   \n",
    "    if cnt== 0:\n",
    "        tmp_X_product_plan = tmp_QTY\n",
    "    else:\n",
    "        tmp_X_product_plan = np.vstack((tmp_X_product_plan, tmp_QTY))\n",
    "    cnt+=1\n",
    "    \n",
    "product_dta = pd.DataFrame(tmp_X_product_plan)\n",
    "product_dta.columns = list(prev_name+post_name+var_name)\n",
    "product_dta['YEAR'] = dt_info[9:end_info,0]\n",
    "product_dta['WW'] = dt_info[9:end_info,1]\n",
    "product_dta['Products'] = r_QTY_sum[9:end_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26aeedb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dta= product_dta.fillna(-999)\n",
    "product_dta= product_dta.replace(0, -999)\n",
    "product_dta.to_csv('./data/X_Product.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eba1930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfce39c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 판매계획/실적 Data Set ####\n",
    "def dta_merge(t_tmp, t_title):\n",
    "    #t_tmp = tmp1 ; t_title = tmp1.columns\n",
    "    ver_col = np.where(t_tmp.columns == 'Version')[0][0]\n",
    "    t_tmp1 = pd.DataFrame(t_tmp.iloc[:,ver_col].copy())\n",
    "    t_tmp1 = pd.concat([t_tmp1,t_tmp.iloc[:, 14:]], axis=1)\n",
    "    return t_tmp1\n",
    "\n",
    "\n",
    "tmp1_title = pd.read_csv('./data/'+f_list[3], skiprows=0, nrows=1)#, header=None)\n",
    "tmp1 = pd.read_csv('./data/'+f_list[3], skiprows=2, thousands=',')\n",
    "#tmp1.columns = tmp1_title.loc[0]\n",
    "#tmp1_dta = column_merge(tmp1, tmp1_title)\n",
    "\n",
    "tmp2_title = pd.read_csv('./data/'+f_list[4], skiprows=0, nrows=1)#, header=None)\n",
    "tmp2 = pd.read_csv('./data/'+f_list[4], skiprows=2, thousands=',')\n",
    "#tmp1_sub.columns = tmp1_sub_title.loc[0]\n",
    "#tmp1_sub_dta = column_merge(tmp1_sub, tmp1_sub_title)\n",
    "\n",
    "tmp1.columns = tmp1_title.loc[0]\n",
    "tmp2.columns = tmp2_title.loc[0]\n",
    "\n",
    "tmp1_name = list(map(lambda i : str('Y')+tmp1_title.columns[i].split('-')[0]+'_'+tmp1_title.iloc[0,i], range(14, len(tmp1_title.loc[0]))))\n",
    "tmp2_name = list(map(lambda i : str('Y')+tmp2_title.columns[i].split('-')[0]+'_'+tmp2_title.iloc[0,i], range(14, len(tmp2_title.loc[0]))))\n",
    "tmp1.columns = list(tmp1.columns[:14]) + tmp1_name\n",
    "tmp2.columns = list(tmp2.columns[:14]) + tmp2_name\n",
    "\n",
    "tmp1 = dta_merge(tmp1, tmp1.columns)\n",
    "tmp2 = dta_merge(tmp2, tmp2.columns)\n",
    "\n",
    "prev_name = list(map(lambda x : 'Prev_Sale_'+str(x), np.arange(8, 0, -1)))\n",
    "post_name = list(map(lambda x : 'Post_Sale_'+str(x), np.arange(1, 9,  1)))\n",
    "var_name  = list(map(lambda x : 'Var_Sale_'+str(x), np.arange(1, 9,  1)))\n",
    "\n",
    "sales_x = []\n",
    "sales_y = []\n",
    "\n",
    "for l in range(9, end_info):#dt_info.shape[0]):\n",
    "    max_week = last_calendar_week(dt_info[l][0])\n",
    "    check_week = str('Y')+str(dt_info[l][0])+'_'+str(max_week)\n",
    "    if (dt_info[l][1] + 8 < max_week) & (dt_info[l][0] == 2020):\n",
    "        tmp_dta = tmp1\n",
    "        tmp_name = list(map(lambda i : str('Y')+tmp1_title.columns[i].split('-')[0]+'_'+tmp1_title.iloc[0,i], range(14, len(tmp1_title.loc[0]))))\n",
    "        #print('tmp1')\n",
    "    else:\n",
    "        tmp_dta = tmp2\n",
    "        tmp_name = list(map(lambda i : str('Y')+tmp2_title.columns[i].split('-')[0]+'_'+tmp2_title.iloc[0,i], range(14, len(tmp2_title.loc[0]))))\n",
    "        if 'Y2021_W53' in tmp_name :\n",
    "            re_col = tmp_name.index('Y2021_W53')#np.where('Y2021_W53' == tmp_name)[0]\n",
    "            tmp_name[re_col] = 'Y2020_W53'        \n",
    "        #print('tmp2')\n",
    "\n",
    "    if check_week in tmp_name:\n",
    "        check_index = tmp_name.index(check_week)\n",
    "        tmp_name[check_index] = (str('Y')+str(dt_info[l][0])+'_W'+str(max_week))\n",
    "    tmp_dta.columns = list(tmp_dta.columns[:1]) + tmp_name\n",
    "    #print(tmp_name)\n",
    "    tmp_row_y = pd.to_datetime(tmp_dta['Version'].str.slice(5,13), format='%Y%m%d').dt.isocalendar().year\n",
    "    tmp_row_w = pd.to_datetime(tmp_dta['Version'].str.slice(5,13), format='%Y%m%d').dt.isocalendar().week\n",
    "    #print(l, dt_info[l])\n",
    "    current_no = np.where((dt_info[l][0] == tmp_row_y) & (dt_info[l][1] == tmp_row_w))[0][0]\n",
    "    prev_no = l - 8\n",
    "    post_no = (l+1) + 8\n",
    "\n",
    "    prev_x = list(map(lambda i : (str('Y')+str(dt_info[i][0])+'_W0'+str(dt_info[i][1])) if np.divmod(dt_info[i][1], 10)[0] == 0 else (str('Y')+str(dt_info[i][0])+'_W'+str(dt_info[i][1])), range(prev_no, l)))\n",
    "    post_x = list(map(lambda i : (str('Y')+str(dt_info[i][0])+'_W0'+str(dt_info[i][1])) if np.divmod(dt_info[i][1], 10)[0] == 0 else (str('Y')+str(dt_info[i][0])+'_W'+str(dt_info[i][1])), range((l+1), post_no)))\n",
    "    current_x = (str('Y')+str(dt_info[l][0])+'_W0'+str(dt_info[l][1])) if np.divmod(dt_info[l][1], 10)[0] == 0 else (str('Y')+str(dt_info[l][0])+'_W'+str(dt_info[l][1]))\n",
    "    \n",
    "    tmp_sale_list = []\n",
    "    tmp_col = np.where(tmp_dta.columns == current_x)[0]\n",
    "    if (current_no+1) < tmp_dta.shape[0]:\n",
    "        if len(tmp_col) == 1:        \n",
    "            tmp_sale_list.append(mode(tmp_dta.iloc[(current_no+1):, tmp_col]).mode[0][0])\n",
    "        else:        \n",
    "            tmp_sale_list.append(mode(tmp_dta.iloc[(current_no+1):, tmp_col].fillna(0).sum(axis=1)).mode[0])\n",
    "    else:\n",
    "        tmp_sale_list.append(0)\n",
    "\n",
    "    tmp_prev_list = []\n",
    "    for i in prev_x:        \n",
    "        tmp_col = np.where(tmp_dta.columns == i)[0]\n",
    "        if len(tmp_col) == 1:\n",
    "            tmp_prev_list.append(tmp_dta.iloc[current_no, tmp_col].values[0])        \n",
    "        else:\n",
    "            tmp_prev_list.append(tmp_dta.iloc[current_no, tmp_col].fillna(0).sum())\n",
    "\n",
    "    tmp_post_list = []\n",
    "    for i in post_x:        \n",
    "        tmp_col = np.where(tmp_dta.columns == i)[0]\n",
    "        if len(tmp_col) == 1:\n",
    "            tmp_post_list.append(tmp_dta.iloc[current_no, tmp_col].values[0])        \n",
    "        else:\n",
    "            tmp_post_list.append(tmp_dta.iloc[current_no, tmp_col].fillna(0).sum())\n",
    "\n",
    "    tmp_var_list = []\n",
    "    for i in range(0, 8):    \n",
    "        tmp_col = np.where(tmp_dta.columns == current_x)[0]        \n",
    "        if len(tmp_col) == 1:\n",
    "            tmp_var_list.append(tmp_dta.iloc[((current_no-1) - i), tmp_col].values[0])\n",
    "        else:\n",
    "            tmp_var_list.append(tmp_dta.iloc[((current_no-1) - i), tmp_col].fillna(0).sum())\n",
    "    #print(tmp_var_list)\n",
    "    tmp_x1 = list(tmp_prev_list + tmp_post_list + tmp_var_list)\n",
    "    tmp_x2 = tmp_sale_list[0]\n",
    "    sales_x.append(tmp_x1)\n",
    "    sales_y.append(tmp_x2)\n",
    "sales_dta = pd.DataFrame(sales_x)\n",
    "\n",
    "sales_dta.columns = list(prev_name+post_name+var_name)#+['Sale'])\n",
    "sales_dta['YEAR'] = dt_info[9:end_info, 0]\n",
    "sales_dta['WW'] = dt_info[9:end_info,1]\n",
    "sales_dta['Sales'] = sales_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6b4ff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_dta = sales_dta.fillna(-999)\n",
    "sales_dta = sales_dta.replace(0, -999)\n",
    "sales_dta = sales_dta.replace(-2, -999)\n",
    "sales_dta = sales_dta.replace(-4, -999)\n",
    "sales_dta.to_csv('./data/X_Sales.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d17eff7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MF_W_20200303_V001'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.to_datetime(tmp1['Version'].str.slice(5,13), format='%Y%m%d').dt.isocalendar().week\n",
    "tmp1['Version'].loc[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb12174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
