{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7fde5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import openpyxl\n",
    "import shutil\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a70599af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3_DAIMLER_E61D_SCP_PRODUCTION_PLANNING_v0512.xlsx', '4_DAIMLER_E61D_SCP_PRODUCTION_RESULT_2018_10_2021_03_v2.xlsx', '5_Daimler_E61D_INVENTORY_210512_v3.xlsx', 'Daimler_MktFcstWaterfall(Mkt Fcst Waterfall)_201901_202003.xlsx', 'Daimler_MktFcstWaterfall(Mkt Fcst Waterfall)_201909_202112.xlsx', 'Daimler_MktFcstWaterfall(Mkt Fcst Waterfall)_202004_202103.xlsx']\n",
      "[0, 1] \n",
      " [3, 4, 5] \n",
      " [2]\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir('./data/.ipynb_checkpoints'):\n",
    "    shutil.rmtree('./data/.ipynb_checkpoints')\n",
    "f_list = os.listdir('./data/')\n",
    "f_list.sort()\n",
    "\n",
    "production_file = [i for i, v in enumerate(f_list) if 'PRODUCTION' in v.split('_')]\n",
    "sale_file = [i for i, v in enumerate(f_list) if 'Fcst' in v.split(' ')]\n",
    "inven_file = [i for i, v in enumerate(f_list) if 'INVENTORY' in v.split('_')]\n",
    "print(f_list)\n",
    "print(production_file, '\\n', sale_file, '\\n', inven_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a432a088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dta_merge(t_tmp, t_title):\n",
    "    #t_tmp = tmp1 ; t_title = tmp1.columns\n",
    "    ver_col = np.where(t_tmp.columns == 'Version')[0][0]\n",
    "    t_tmp1 = pd.DataFrame(t_tmp.iloc[:,ver_col].copy())\n",
    "    t_tmp1 = pd.concat([t_tmp1,t_tmp.iloc[:, 14:]], axis=1)\n",
    "    return t_tmp1\n",
    "def year_week_cal(tmp_set_, col_name_, format_):\n",
    "    tmp_cal_year = list(pd.to_datetime(tmp_set_[col_name_], format=format_).dt.isocalendar().year.values)\n",
    "    tmp_cal_ww   = pd.to_datetime(tmp_set_[col_name_], format=format_).dt.isocalendar().week.values\n",
    "    tmp_cal_ww1 = list(map(lambda x : str(tmp_cal_ww[x]) if divmod(tmp_cal_ww[x], 10)[0] > 0 else str(0)+str(tmp_cal_ww[x]), range(0, len(tmp_cal_year))))\n",
    "    tmp_cal_date = list(map(lambda x : str(tmp_cal_year[x]) + tmp_cal_ww1[x], range(0, len(tmp_cal_year))))\n",
    "    return tmp_cal_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e8d321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Complete : Inven_3xxC.csv\n",
      "Save Complete : Inven_3xxT.csv\n",
      "Save Complete : Inven_5xx0.csv\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(inven_file)):\n",
    "    tmp_file_raw = openpyxl.load_workbook('./data/'+f_list[inven_file[i]])\n",
    "    sheet_name = '02. 일별 PSI 트렌드' #tmp_file_raw.sheetnames\n",
    "    tmp_file_pd = pd.DataFrame(tmp_file_raw[sheet_name].values).copy()\n",
    "    tmp_col_name1 = list(tmp_file_pd.iloc[0,0:])\n",
    "    tmp_file = tmp_file_pd.iloc[1:,:].copy().reset_index(drop=True)\n",
    "    tmp_file.columns = tmp_col_name1\n",
    "    tmp_day = pd.to_datetime(tmp_file['연월일'], format='%Y년%m월%d일').dt.isocalendar().day\n",
    "    tmp_file1 = tmp_file[(tmp_file['자재'].str.slice(0,9) == 'ACEN1060I') & (tmp_day == 7)].copy()\n",
    "    inven_filter_ = [['3', 'C'], ['3','T'],['5','0']]\n",
    "    for k in range(0, len(inven_filter_)):\n",
    "        tmp_store1, tmp_store2 = inven_filter_[k][0], inven_filter_[k][1]\n",
    "        tmp_file1_sub1 = tmp_file1[(tmp_file1['저장위치'].str.slice(0,1) == tmp_store1)&(tmp_file1['저장위치'].str.slice(3,4) == tmp_store2)].copy()\n",
    "        tmp_week_ = year_week_cal(tmp_file1_sub1, '연월일', '%Y년%m월%d일')\n",
    "        tmp_file1_sub1['Inven Week'] = tmp_week_\n",
    "        tmp_file1_sub1['Date'] = np.datetime_as_string(pd.to_datetime(tmp_file1_sub1['연월일'], format='%Y년%m월%d일'), unit='D')\n",
    "        tmp_file1_sub1 = tmp_file1_sub1[['Inven Week','Date','재고수량']]\n",
    "        tmp_group = tmp_file1_sub1.groupby(['Inven Week','Date'])\n",
    "        tmp_sum = pd.DataFrame(tmp_group.sum())\n",
    "        tmp_sum.reset_index(inplace=True)    \n",
    "        tmp_sum.to_csv('./data1/Inven_%sxx%s.csv'%(tmp_store1, tmp_store2), index=False)\n",
    "        print('Save Complete : Inven_%sxx%s.csv'%(tmp_store1, tmp_store2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc0f9e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(production_file)): #1):#\n",
    "    tmp_file_raw = openpyxl.load_workbook('./data/'+f_list[production_file[i]])\n",
    "    if 'RESULT' in f_list[production_file[i]].split('_'):   \n",
    "        sheet_name = '02.Detail_생산계획 준수율'\n",
    "        tmp_file_pd = pd.DataFrame(tmp_file_raw[sheet_name].values).copy()\n",
    "        tmp_col_name1 = list(tmp_file_pd.iloc[5,0:])\n",
    "        tmp_file = tmp_file_pd.iloc[6:, :].copy().reset_index(drop=True)\n",
    "        tmp_file.columns = tmp_col_name1\n",
    "        tmp_file1 = tmp_file[(tmp_file['Material'].str.slice(0,9)=='ACEN1060I') & (tmp_file['Nick Name'].str.slice(0,4)=='E61D')].copy().reset_index(drop=True)\n",
    "        tmp_file1 = tmp_file1[['Plan Date', 'Plan Week', 'Basic Date', 'Result Qty']] #'Plan Date', \n",
    "        #tmp_file1['WW'] = pd.to_datetime(tmp_file1['Plan Date']).dt.isocalendar().week\n",
    "        tmp_file1 = tmp_file1[['Plan Week', 'Basic Date', 'Result Qty']] #'Plan Date', \n",
    "        tmp_group = tmp_file1.groupby(['Plan Week', 'Basic Date'])\n",
    "        tmp_g_sum = pd.DataFrame(tmp_group.sum())\n",
    "        tmp_g_sum.reset_index(inplace=True)\n",
    "        #tmp_g_cnt = pd.DataFrame(tmp_group.count())\n",
    "        #tmp_g_cnt.reset_index(inplace=True)\n",
    "        tmp_g = tmp_g_sum#pd.merge(tmp_g_sum, tmp_g_cnt, on=['Plan Week', 'WW'])\n",
    "    else:        \n",
    "        sheet_name = 'DynamicResult'\n",
    "        tmp_file_pd = pd.DataFrame(tmp_file_raw[sheet_name].values).copy()\n",
    "        tmp_col_name1 = list(tmp_file_pd.iloc[0,0:])\n",
    "        tmp_file = tmp_file_pd.iloc[1:, :].copy().reset_index(drop=True)\n",
    "        tmp_file.columns = tmp_col_name1\n",
    "        tmp_file1 = tmp_file[['PLAN_START_YYYYMMDD', 'YYYYMMDD', 'QTY']].copy() #'Plan Date', \n",
    "        tmp_plan_date_= year_week_cal(tmp_file1, 'PLAN_START_YYYYMMDD', '%Y%m%d')\n",
    "        tmp_date_= year_week_cal(tmp_file1, 'YYYYMMDD', '%Y%m%d')\n",
    "        tmp_file1['WW'] = tmp_plan_date_\n",
    "        tmp_file1['tWW']=tmp_date_\n",
    "        tmp_file1['Date'] = np.datetime_as_string(pd.to_datetime(tmp_file['PLAN_START_YYYYMMDD'], format='%Y%m%d'), unit='D')\n",
    "        tmp_file1 = tmp_file1[['WW', 'Date', 'tWW', 'QTY']] #'PLAN_START_YYYYMMDD', 'YYYYMMDD', \n",
    "        tmp_group = tmp_file1.groupby(['WW', 'Date', 'tWW'])\n",
    "        tmp_g_sum = pd.DataFrame(tmp_group.sum())\n",
    "        tmp_g_sum.reset_index(inplace=True)\n",
    "        #tmp_g_cnt = pd.DataFrame(tmp_group.count())\n",
    "        #tmp_g_cnt.reset_index(inplace=True)\n",
    "        tmp_g = tmp_g_sum #pd.merge(tmp_g_sum, tmp_g_cnt, on=['Plan Date', 'Date'])\n",
    "    tmp_g.to_csv('./data1/'+sheet_name+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de822f59",
   "metadata": {},
   "source": [
    "###### Planning에만 적용\n",
    "tmp_ = tmp_g[tmp_g['Plan Date'] == '202113']\n",
    "test = list(map(lambda x : [tmp_['Date'].values[x], str(tmp_['QTY'].values[x])], range(0, tmp_.shape[0])))\n",
    "test_join = '/'.join(list(map(lambda x : ','.join(test[x]), range(0, tmp_.shape[0]))))\n",
    "print(len(test_join), '\\n', test_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e203d991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daimler_MktFcstWaterfall(Mkt Fcst Waterfall)_201901_202003.xlsx\n",
      "Daimler_MktFcstWaterfall(Mkt Fcst Waterfall)_201909_202112.xlsx\n",
      "Daimler_MktFcstWaterfall(Mkt Fcst Waterfall)_202004_202103.xlsx\n"
     ]
    }
   ],
   "source": [
    "for f in range(0, len(sale_file)):    \n",
    "    tmp_file_raw = openpyxl.load_workbook('./data/'+f_list[sale_file[f]])\n",
    "    sheet_name = 'Mkt Fcst Waterfall'\n",
    "    tmp_file = pd.DataFrame(tmp_file_raw[sheet_name].values)\n",
    "    ind_col = np.where(tmp_file.iloc[0, :] == 'Measure')[0][0]\n",
    "    col_name1 = list(tmp_file.iloc[0,:(ind_col+1)])\n",
    "    tmp_col_name2 = list(tmp_file.iloc[0,(ind_col+1):])\n",
    "    tmp_col_name2_ = []\n",
    "    if None in tmp_col_name2:\n",
    "        for i in range(0, len(tmp_col_name2)):    \n",
    "            if tmp_col_name2[i] is not None:\n",
    "                tmp_base = tmp_col_name2[i]\n",
    "            tmp_col_name2_.append(tmp_base)\n",
    "    else:\n",
    "        tmp_col_name2_ = tmp_col_name2\n",
    "\n",
    "    tmp_col_name3 = list(tmp_file.iloc[1,(ind_col+1):])\n",
    "    col_name2 = []\n",
    "    for i in range(0, len(tmp_col_name3)):\n",
    "        if tmp_col_name3[i] == \"SUM\":\n",
    "            col_name2.append(tmp_col_name3[i])\n",
    "        else:\n",
    "            if tmp_col_name2_[i][5:] == '12' and tmp_col_name3[i][1:] == '01':\n",
    "                col_name2.append(str(int(tmp_col_name2_[i][:4])+1)+tmp_col_name3[i][1:])\n",
    "            elif tmp_col_name2_[i][5:] == '01' and tmp_col_name3[i][1:] == '53':\n",
    "                col_name2.append(str(int(tmp_col_name2_[i][:4])-1)+tmp_col_name3[i][1:])                \n",
    "            else:\n",
    "                col_name2.append(tmp_col_name2_[i][:4]+tmp_col_name3[i][1:])\n",
    "    col_name = col_name1 + col_name2\n",
    "    tmp_file1 = tmp_file.iloc[3:,:].reset_index(drop=True).copy()\n",
    "    tmp_file1.columns = col_name\n",
    "    if 'SUM' in col_name:\n",
    "        rm_col1 = np.array([i for i, val in enumerate(col_name) if val == 'SUM'])\n",
    "        tmp_file1.drop(tmp_file1.iloc[:, rm_col1], axis=1, inplace=True)\n",
    "    keep_col_name = list(['Version']) + sorted(list(set(tmp_file1.columns[(ind_col+1):])))\n",
    "    tmp_file1 = tmp_file1[keep_col_name].copy()\n",
    "    tmp_file1_title = tmp_file1.columns.unique()\n",
    "    tmp_file2_val = tmp_file1['Version'].copy()\n",
    "    for k in range(1, len(tmp_file1_title)):\n",
    "        tmp_i = [i for i, val in enumerate(tmp_file1.columns) if val == tmp_file1_title[k] ]\n",
    "        #print(k, tmp_i, tmp_file1_title[k])\n",
    "        if len(tmp_i) > 1:\n",
    "            #tmp_file2.append(list(())\n",
    "            tmp_file2_val = pd.concat([tmp_file2_val, tmp_file1.iloc[:,tmp_i].fillna(0).sum(axis=1)], axis=1)\n",
    "        else :\n",
    "            tmp_file2_val = pd.concat([tmp_file2_val, tmp_file1.iloc[:,tmp_i].fillna(0)], axis=1)\n",
    "    tmp_file2_val.columns = tmp_file1_title\n",
    "    if any(tmp_file2_val['Version'] == 'CURRENT'):\n",
    "        tmp_file2_val = tmp_file2_val[tmp_file2_val['Version'] != 'CURRENT']    \n",
    "    tmp_file2_val = tmp_file2_val.reset_index(drop=True)\n",
    "    \n",
    "    tmp_file2 = pd.DataFrame({'WW' : year_week_cal(tmp_file2_val, 'Version', 'MF_W_%Y%m%d_V001')})\n",
    "    tmp_file2['Date'] = np.datetime_as_string(pd.to_datetime(tmp_file2_val['Version'], format='MF_W_%Y%m%d_V001'), unit='D')\n",
    "    #list(map(lambda x: pd.to_datetime(tmp_file2_val['Version'], format='MF_W_%Y%m%d_V001').loc[x].strftime('%Y%m%d'), range(0, tmp_file2.shape[0])))\n",
    "    tmp_file2 = pd.concat([tmp_file2, tmp_file2_val.drop(['Version'], axis=1)], axis=1)\n",
    "    tmp_file2 = tmp_file2.sort_values(by=['Date'], axis=0)\n",
    "    tmp_group = tmp_file2.groupby(['WW', 'Date'])\n",
    "    tmp_g_sum = pd.DataFrame(tmp_group.sum())\n",
    "    tmp_g_sum = tmp_g_sum.sort_index(axis=1)\n",
    "    tmp_g_sum.reset_index(inplace=True)\n",
    "    tmp_g_sum.to_csv('./data1/'+f_list[sale_file[f]]+'.csv', index=False)\n",
    "    print(f_list[sale_file[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33e4178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
